# AWS-Project building pipelines
1.Created docker-compose.yaml file to store architecture master and worker specifications
2.docker compose up -d->starts master and 4 workers->check in docker UI->container is created aws-project
3.In streamingwithunstructureddata.py spark specifications ,aws credentials are added
4.we will have input as 5 different files-csv,img,json,pdf,text,video
4.udf_utils.py will have fields defined
